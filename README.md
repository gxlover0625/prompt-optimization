# prompt-optimization



## Update
0714, agent base & chat function
```python
from common import backend

cfg = {
    "backend": "ollama",
    "model": "qwen2:7b",
    "api_key": "sk-proj-1234567890",
    "base_url": "http://localhost:11434/v1",
}

llm = backend[cfg['backend']](cfg)
print(llm.chat("ä½ å¥½"))
```
- coreæ˜¯æŠ½è±¡ç±»ï¼Œä¸»è¦æœ‰LLMåŸºç±»å’Œå®ƒçš„chatæ¥å£ã€AgentåŸºç±»å’Œå®ƒçš„runæ¥å£ã€ExecutionAgentåŸºç±»å’Œå®ƒçš„executeæ¥å£
- commonæ˜¯å…·ä½“å®ç°ï¼ŒåŒ…æ‹¬LLMåŸºç±»çš„ä¸‰ä¸ªå…·ä½“å®ç°ï¼Œollamaã€openaiã€vllm
- datasetå¤„ç†æ•°æ®
- piplineå¯¹åº”å®Œæ•´æ–¹æ³•

## ğŸ¤ Acknowledgements
We were inspired by the excellent open-source project [OpenCompass](https://github.com/open-compass/opencompass), which helped simplify our development. Additionally, we would like to thank the following open-source projects for their code contributions.
- [OpenCompass](https://github.com/open-compass/opencompass), is an LLM evaluation platform, supporting a wide range of models (Llama3, Mistral, InternLM2,GPT-4,LLaMa2, Qwen,GLM, Claude, etc) over 100+ datasets.