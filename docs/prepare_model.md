# Model Preparation

## Supported Backends
- [vllm](https://docs.vllm.ai/en/latest/getting_started/quickstart.html), A high-throughput and memory-efficient inference and serving engine for LLMs
- [ollama](https://ollama.com/), get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 3, Mistral Small 3.1 and other large language models.
- [OpenAI-Compatible](https://github.com/openai/openai-python), the official Python library for the OpenAI API

## vllm
### Installation
Please refer to the [vllm installation](https://docs.vllm.ai/en/latest/getting_started/installation/index.html).
